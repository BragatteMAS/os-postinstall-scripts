---
phase: 17-test-expansion-bash
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/test-core-platform.bats
  - tests/test-core-progress.bats
  - tests/test-core-interactive.bats
autonomous: true

must_haves:
  truths:
    - "platform.sh detect_platform correctly identifies OS, arch, and package manager under mocked conditions"
    - "platform.sh verify_bash_version passes on Bash 5 and verify_package_manager rejects empty DETECTED_PKG"
    - "progress.sh show_dry_run_banner outputs banner only when DRY_RUN=true"
    - "progress.sh count_platform_steps counts platform-relevant files from fixture profiles"
    - "progress.sh show_completion_summary shows duration, profile, and failure count"
    - "interactive.sh show_category_menu and ask_tool return 0 in non-interactive mode"
  artifacts:
    - path: "tests/test-core-platform.bats"
      provides: "Unit tests for all 7 platform.sh exported functions"
      min_lines: 150
    - path: "tests/test-core-progress.bats"
      provides: "Unit tests for all 3 progress.sh exported functions"
      min_lines: 100
    - path: "tests/test-core-interactive.bats"
      provides: "Unit tests for both interactive.sh exported functions"
      min_lines: 50
  key_links:
    - from: "tests/test-core-platform.bats"
      to: "src/core/platform.sh"
      via: "source in setup()"
      pattern: 'source.*platform\.sh'
    - from: "tests/test-core-progress.bats"
      to: "src/core/progress.sh"
      via: "source in setup() with errors.sh dependency"
      pattern: 'source.*progress\.sh'
    - from: "tests/test-core-interactive.bats"
      to: "src/core/interactive.sh"
      via: "source in setup()"
      pattern: 'source.*interactive\.sh'
---

<objective>
Create bats unit tests for platform.sh (~15-18 tests), progress.sh (~10-12 tests), and interactive.sh (~6-8 tests).

Purpose: Cover 3 of 4 untested core modules with the established project test pattern. These modules are mocking-heavy (uname, command -v) and dependency-chain-heavy (progress depends on logging+errors), requiring verified patterns from research.
Output: 3 new .bats files with ~31-38 total tests passing.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/17-test-expansion-bash/17-RESEARCH.md

@tests/test-core-errors.bats
@src/core/platform.sh
@src/core/progress.sh
@src/core/interactive.sh
@src/core/logging.sh
@src/core/errors.sh
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create test-core-platform.bats (~15-18 tests)</name>
  <files>tests/test-core-platform.bats</files>
  <action>
Create `tests/test-core-platform.bats` following the exact project test pattern from test-core-errors.bats.

**setup() function:**
- `export NO_COLOR=1`
- `unset _PLATFORM_SOURCED _LOGGING_SOURCED`
- Define `uname()` mock that dispatches on `$1`: `-s` returns "Linux", `-m` returns "x86_64", `*` returns "Linux". Use `export -f uname`.
- Define `command()` mock using `_MOCK_COMMANDS` array pattern (default: `("apt-get")`). Intercept `-v` flag only, passthrough everything else with `builtin command "$@"`. Use `export -f command`.
- Source `logging.sh` then `platform.sh` from `${BATS_TEST_DIRNAME}/../src/core/`

**Tests to write (in this order):**

detect_platform OS detection (4 tests):
1. `detect_platform sets DETECTED_OS=linux for uname=Linux` - default mock
2. `detect_platform sets DETECTED_OS=macos for uname=Darwin` - override uname -s to return "Darwin", export -f, re-source platform.sh (unset _PLATFORM_SOURCED first), call detect_platform, assert `$DETECTED_OS` == "macos"
3. `detect_platform sets DETECTED_OS=windows for uname=MINGW` - mock returns "MINGW64_NT-10.0"
4. `detect_platform sets DETECTED_OS=unknown for unsupported uname` - mock returns "FreeBSD"

detect_platform architecture (3 tests):
5. `detect_platform sets DETECTED_ARCH=x86_64` - default mock
6. `detect_platform sets DETECTED_ARCH=arm64 for arm64` - override uname -m to "arm64"
7. `detect_platform normalizes aarch64 to arm64` - override uname -m to "aarch64"

detect_platform package manager (3 tests):
8. `detect_platform sets DETECTED_PKG=apt when apt-get available` - default mock (apt-get in _MOCK_COMMANDS)
9. `detect_platform sets DETECTED_PKG=brew when brew available` - set `_MOCK_COMMANDS=("brew")`
10. `detect_platform sets DETECTED_PKG empty when no package manager` - set `_MOCK_COMMANDS=()`

detect_platform bash version (1 test):
11. `detect_platform sets DETECTED_BASH from BASH_VERSINFO` - just verify it is not empty and contains a dot (e.g., "5.2")

verify_bash_version (1 test):
12. `verify_bash_version passes with current Bash` - run verify_bash_version, assert_success (we are on Bash 5.x, cannot test <4 path since BASH_VERSINFO is readonly)

verify_supported_distro (3 tests):
13. `verify_supported_distro passes for macOS` - set DETECTED_OS=macos, run, assert_success
14. `verify_supported_distro passes for ubuntu` - set DETECTED_OS=linux DETECTED_DISTRO=ubuntu, run, assert_success
15. `verify_supported_distro continues for unsupported distro in non-TTY` - set DETECTED_OS=linux DETECTED_DISTRO=arch, run (bats is non-TTY so it hits the `! -t 0` path), assert_success, assert_output --partial "not officially supported"

verify_package_manager (2 tests):
16. `verify_package_manager fails when DETECTED_PKG empty` - set DETECTED_PKG="", run, assert_failure
17. `verify_package_manager passes when DETECTED_PKG=apt` - set DETECTED_PKG=apt, run, assert_success

request_sudo (1 test):
18. `request_sudo skips in DRY_RUN mode` - DRY_RUN=true, run request_sudo, assert_success, assert_output --partial "skipping sudo"

**IMPORTANT notes:**
- For tests 2-4 (OS detection) and 6-7 (arch): each test must re-define the uname mock, `export -f uname`, `unset _PLATFORM_SOURCED`, re-source `platform.sh`, THEN call `detect_platform`. The mock must be set BEFORE sourcing because `detect_platform` is called explicitly, not at source time.
- Actually, `detect_platform` is NOT called at source time -- it is just defined. So the mock only needs to exist before `detect_platform` is called. Override in the test body, then call `detect_platform`.
- Do NOT test `check_internet` with real curl -- skip it or mock curl to fail.
- For test 10 (no pkg manager), the command mock must return 1 for ALL `-v` checks.
  </action>
  <verify>
Run: `./tests/lib/bats-core/bin/bats tests/test-core-platform.bats`
All 15-18 tests pass (0 failures).
  </verify>
  <done>test-core-platform.bats exists with 15+ passing tests covering detect_platform (OS, arch, pkg mgr, bash), verify_bash_version, verify_supported_distro, verify_package_manager, and request_sudo.</done>
</task>

<task type="auto">
  <name>Task 2: Create test-core-progress.bats (~10-12 tests) and test-core-interactive.bats (~6-8 tests)</name>
  <files>tests/test-core-progress.bats, tests/test-core-interactive.bats</files>
  <action>
**File 1: tests/test-core-progress.bats**

**setup() function:**
- `export NO_COLOR=1`
- `unset _LOGGING_SOURCED _ERRORS_SOURCED _PROGRESS_SOURCED`
- Source `logging.sh`, then `errors.sh`, then `progress.sh` (full dependency chain -- verified in research)
- `clear_failures`
- `SECONDS=90` (mock elapsed time)
- `FAILURE_LOG="$(mktemp)"`
- `export FAILURE_LOG`

**teardown():** `rm -f "$FAILURE_LOG"`

**Tests:**

show_dry_run_banner (3 tests):
1. `show_dry_run_banner outputs banner when DRY_RUN=true` - DRY_RUN=true, run, assert_success, assert_output --partial "DRY RUN MODE"
2. `show_dry_run_banner outputs nothing when DRY_RUN unset` - unset DRY_RUN, run, assert_success, assert_output "" (empty)
3. `show_dry_run_banner outputs nothing when DRY_RUN=false` - DRY_RUN=false, run, assert_success, assert_output ""

count_platform_steps (5 tests):
4. `count_platform_steps counts linux-relevant files` - create fixture profile in `$BATS_TEST_TMPDIR` with "apt.txt\nbrew.txt\ncargo.txt\nwinget.txt\nflatpak.txt", run with "linux", assert_output "3" (apt + cargo + flatpak)
5. `count_platform_steps counts macos-relevant files` - same fixture, run with "macos", assert_output "1" (brew only)
6. `count_platform_steps returns 0 for missing file` - run with nonexistent path, assert_output "0"
7. `count_platform_steps returns 0 for empty profile` - empty file, assert_output "0"
8. `count_platform_steps skips comments` - file with only "# comment" lines, assert_output "0"

show_completion_summary (4 tests):
9. `show_completion_summary shows success with no failures` - clear_failures, empty FAILURE_LOG, run show_completion_summary "developer" "macos", assert_output --partial "All sections completed successfully"
10. `show_completion_summary shows failure count` - echo "failed-pkg" > "$FAILURE_LOG", run show_completion_summary "developer" "linux", assert_output --partial "1 failure"
11. `show_completion_summary shows dry-run label` - DRY_RUN=true, run show_completion_summary "developer" "linux", assert_output --partial "Dry Run Complete"
12. `show_completion_summary shows profile and platform` - run show_completion_summary "minimal" "macos", assert_output --partial "minimal", assert_output --partial "macos"

---

**File 2: tests/test-core-interactive.bats**

**setup() function:**
- `export NO_COLOR=1`
- `unset _INTERACTIVE_SOURCED _LOGGING_SOURCED`
- Source `logging.sh` then `interactive.sh`

**Tests:**

show_category_menu (3 tests):
1. `show_category_menu returns 0 with NONINTERACTIVE=true` - NONINTERACTIVE=true, run show_category_menu "DevTools" "dev tools", assert_success
2. `show_category_menu returns 0 when stdin not TTY` - unset NONINTERACTIVE, run show_category_menu "DevTools", assert_success (bats stdin is not TTY, hits `! -t 0` path)
3. `show_category_menu returns 0 with default category name` - NONINTERACTIVE=true, run show_category_menu, assert_success

ask_tool (3 tests):
4. `ask_tool returns 0 with NONINTERACTIVE=true` - NONINTERACTIVE=true, run ask_tool "ripgrep", assert_success
5. `ask_tool returns 0 when stdin not TTY` - unset NONINTERACTIVE, run ask_tool "ripgrep", assert_success
6. `ask_tool returns 0 with default tool name` - NONINTERACTIVE=true, run ask_tool, assert_success

**Note on output testing:** Both functions return 0 early in non-interactive mode BEFORE echoing any menu text. Do NOT assert_output for menu content -- only test return codes. The research confirmed this: "show_category_menu echoes AFTER the TTY check, [non-interactive] returns 0 early."
  </action>
  <verify>
Run: `./tests/lib/bats-core/bin/bats tests/test-core-progress.bats tests/test-core-interactive.bats`
All tests pass (0 failures). Expected: ~12 progress + ~6 interactive = ~18 tests.
  </verify>
  <done>test-core-progress.bats exists with 12 passing tests covering show_dry_run_banner, count_platform_steps, and show_completion_summary. test-core-interactive.bats exists with 6 passing tests covering show_category_menu and ask_tool non-interactive paths.</done>
</task>

</tasks>

<verification>
Run all new test files together:
```bash
./tests/lib/bats-core/bin/bats tests/test-core-platform.bats tests/test-core-progress.bats tests/test-core-interactive.bats
```
Expected: ~33-36 tests, 0 failures.

Then run ALL existing + new tests to confirm no regressions:
```bash
./tests/lib/bats-core/bin/bats tests/test-core-*.bats
```
Expected: ~77-82 total tests (44 existing + 33-36 new), 0 failures.
</verification>

<success_criteria>
- test-core-platform.bats: 15+ tests passing (TEST-03)
- test-core-progress.bats: 10+ tests passing (TEST-04)
- test-core-interactive.bats: 6+ tests passing (TEST-06)
- All existing tests still pass (no regressions)
- All tests follow established project pattern (load, setup with unset guards, NO_COLOR, source chain)
</success_criteria>

<output>
After completion, create `.planning/phases/17-test-expansion-bash/17-01-SUMMARY.md`
</output>
